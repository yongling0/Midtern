name: API Web Scraper Workflow

on:
  schedule:
    - cron: '0 10 * * *' # 每日 UTC 時間 10:00 執行
  workflow_dispatch:

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
      # 檢出 GitHub Repository
      - name: Checkout repository
        uses: actions/checkout@v2

      # 設定 Python 環境
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'

      # 安裝所需的 Python 套件（檢查 requirements.txt 是否存在）
      - name: Install dependencies
        run: |
          if [ -f requirements.txt ]; then
            python -m pip install --upgrade pip
            pip install --force-reinstall -r requirements.txt || echo "Requirements installation failed"
          else
            echo "requirements.txt not found, skipping installation"
          fi

      # 執行靜態爬蟲程式（檢查 api.py 是否存在）
      - name: Run api.py script
        run: |
          if [ -f api.py ]; then
            python api.py || echo "::error::API execution failed"
          else
            echo "api.py not found, skipping execution"
          fi

      # 保存執行日誌到資料夾（失敗時）
      - name: Save logs to folder
        if: ${{ failure() }}
        run: |
          mkdir -p logs && mv *.log logs/ || echo "No log files found"

      # 上傳執行日誌（失敗時）
      - name: Upload logs as artifact
        if: ${{ failure() }}
        uses: actions/upload-artifact@v4 # 使用最新穩定版本 v3
        with:
          name: execution-logs
          path: logs/ 
